<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document</title>
</head>
<body>
    
<div class="flex justify-center bg-black">
    <nav class="self-center w-full max-w-7xl  ">
        <div class="flex flex-col lg:flex-row justify-around items-center text-white">
            <h1 class="uppercase pl-5 py-4 text-lg font-sans font-bold"><strong>Teachable Machine</strong></h1>
            <ul class="hidden lg:flex items-center text-[18px] font-semibold pl-32">
                <li class="hover:underline  underline-offset-4 decoration-2 decoration-white py-2 rounded-lg px-5">
                    <a href="#">Home</a>
                </li>
                <li class="hover:underline underline-offset-4 decoration-2 decoration-white py-2 rounded-lg px-5"><a
                        href="#">Contact</a></li>
                <li class="hover:underline underline-offset-4 decoration-2 decoration-white py-2 rounded-lg px-5"><a
                        href="#">Services</a></li>
                <li class="hover:underline underline-offset-4 decoration-2 decoration-white py-2 rounded-lg px-5"><a
                        href="#">About</a></li>
                <li class="hover:underline underline-offset-4 decoration-2 decoration-white py-2 rounded-lg px-5"><a
                        href="#">Pricing</a></li>
            </ul>
            <div class="text-white text-center text-base pr-5  inline-flex"> <a href="#"
                    class="w-8 h-8 inline-block rounded-full pt-[6px] hover:text-blue-500"><i
                        class="fa fa-twitter"></i></a> <a href="#"
                    class="w-8 h-8 inline-block rounded-full pt-[5px] hover:text-blue-500"><i
                        class="fa fa-instagram"></i></a> <a href="#"
                    class="w-8 h-8 inline-block rounded-full pt-[5px] hover:text-blue-500"><i
                        class="fa fa-facebook"></i></a> <a href="#"
                    class="w-8 h-8 inline-block rounded-full pt-[5px] hover:text-blue-500"><i
                        class="fa fa-google"></i></a> <a href="#"
                    class="w-8 h-8 inline-block rounded-full pt-[5px] hover:text-blue-500"><i
                        class="fa fa-linkedin"></i></a> </div>
        </div>
    </nav>
</div>
<div class="flex justify-center bg-black p-8 ">
    <div class="flex flex-col justify-center">

        <div class="flex flex-col lg:flex-row max-w-7xl justify-center items-center p-2 space-y-3 w-full">
            <div class="flex flex-col  text-white md:items-start items-center justify-between  space-y-3 px-8">
                <div class="text-5xl md:text-7xl font-bold ">
                    Teachable Machine</div>
                <div class="text-xl  md:text-3xl   ">
                    Train a computer to recognize your own images, sounds, & poses.</div>
                <div class="text-xl md:text-3xl   ">
                    A fast, easy way to create machine learning models for your sites, apps, and more â€“ no expertise or coding required.</div>
            </div>
            <a href="#" class="flex text-black bg-gradient-to-tr from-green-300 via-blue-500 to-purple-600 rounded-lg py-1 px-2 m-2 font-right side hover:text-white border-black border"> <ion-icon name="logo-google-playstore" class="m-1 text-xl"></ion-icon> <div>Get Start</div> </a> <script type="module" src="https://unpkg.com/ionicons@5.5.2/dist/ionicons/ionicons.esm.js"></script> <script nomodule src="https://unpkg.com/ionicons@5.5.2/dist/ionicons/ionicons.js"></script> 
            <video width="900" height="1200" controls>
                <source src="./image/WhatsApp Video 2024-01-24 at 10.18.10 PM.mp4" type="video/mp4">
                <source src="movie.ogg" type="video/ogg">
                Your browser does not support the video tag.
              </video>


              
           <!--- <link rel="shortcut icon" href="/assets/img/favicon.png">
            <div class="flex space-x-2 md:space-x-6 md:m-4">

                <div class="md:w-20 w-10 h-60 md:h-96  overflow-hidden rounded-xl">
                    <img src="https://source.unsplash.com/100x400/?man" class="h-full w-full" alt="">
                </div>
                <div class="md:w-60 w-28 h-60 md:h-96  overflow-hidden rounded-xl">
                    <img src="https://source.unsplash.com/200x400/?girl" class="h-full w-full" alt="">

                </div>
                <div class="md:w-28  w-16 h-60 md:h-96  overflow-hidden rounded-xl">
                    <img src="https://source.unsplash.com/100x400/?boy" class="h-full w-full" alt="">

                </div>
                <div class="md:w-20 w-10 h-60 md:h-96  overflow-hidden rounded-xl">
                    <img src="https://source.unsplash.com/100x400/?women" class="h-full w-full" alt="">

                </div>
            </div>-->

        </div>
    </div>
    
</div>
<section class="text-gray-600 body-font">
    <div class="container px-5 py-24 mx-auto flex flex-col">
      <div class="lg:w-4/6 mx-auto">
        <div class="rounded-lg h-64 overflow-hidden">
            <video width="1300" height="1200" controls>
                <source src="./image/WhatsApp Video 2024-01-24 at 10.18.10 PM.mp4" type="video/mp4">
                <source src="movie.ogg" type="video/ogg">
                Your browser does not support the video tag.
              </video>
        </div>
       <!--- <div class="flex flex-col sm:flex-row mt-10">
          <div class="sm:w-1/3 text-center sm:pr-8 sm:py-8">
            <div class="w-20 h-20 rounded-full inline-flex items-center justify-center bg-gray-200 text-gray-400">
              <svg fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" class="w-10 h-10" viewBox="0 0 24 24">
                <path d="M20 21v-2a4 4 0 00-4-4H8a4 4 0 00-4 4v2"></path>
                <circle cx="12" cy="7" r="4"></circle>
              </svg>
            </div>-->
           <!--- <div class="flex flex-col items-center text-center justify-center">
              <h2 class="center title-font mt-4 text-gray-900 text-lg">What is TeachableMachine</h2>
              <div class="w-12 h-1 bg-indigo-500 rounded mt-2 mb-4"></div>
              <p class="text-base">Raclette knausgaard hella meggs normcore williamsburg enamel pin sartorial venmo tbh hot chicken gentrify portland.</p>
            </div>-->
          </div>
          <div class="sm:w-2/3 sm:pl-8 sm:py-8 sm: border-gray-200 sm:border-t-0 border-t mt-4 pt-4 sm:mt-0 text-center sm:text-left">
            <p class="leading-relaxed text-lg mb-4"><div class="class"></div><center><strong><b>What is TeachableMachine?</b></strong></center></p>
            <p>Teachable Machine is a web-based tool that makes creating machine learning models fast, easy, and accessible to everyone.</p>
            <!--<a class="text-indigo-500 inline-flex items-center">Teachable Machine is a web-based tool that makes creating machine learning models fast, easy, and accessible to everyone.
              <svg fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" class="w-4 h-4 ml-2" viewBox="0 0 24 24">-->
                
              </svg>
            </a>
          </div>
        </div>
      </div>
    </div>
  </section>
<div class="flex justify-center bg-blue-500 p-4">
    <div class="flex flex-col justify-center items-center ">
        <div class="text-white text-3xl font-medium">How do I use it?</div>
        <div class="flex flex-col md:flex-row max-w-7xl justify-center items-center ">

            <div class="overflow-hidden w-full m-4 flex justify-center bg-white rounded-lg  md:w-[33%] px-8">

                <div class="flex flex-col md:flex-row items-center justify-center  ">
                    <div class="  items-center justify-center flex py-2">
                        <div class="flex flex-col  items-center justify-center text-center">
                            <img src="./image/download (1) (1) (1).png" alt="" class="rounded-full" />
                            <div class="font-bold">1-Gather</div>
                            <div class="text-stone-600 font-medium m-2"> Gather and group your examples into classes, or categories, that you want the computer to learn.</div>
                            
                            
                        </div>
                    </div>

                </div>
            </div>
            <div class="overflow-hidden w-full m-4 flex justify-center bg-white rounded-lg  md:w-[33%] px-8">

                <div class="flex flex-col md:flex-row items-center justify-center  ">
                    <div class="  items-center justify-center flex py-2">
                        <div class="flex flex-col  items-center justify-center text-center">
                            <img src="./image/download (2) (1).png" alt="" class="rounded-full" />
                            <div class="font-bold">2-Train</div>
                            <div class="text-stone-600 font-medium m-2"> Train your model, then instantly test it out to see whether it can correctly classify new examples.</div>
                            
                            
                        </div>
                    </div>

                </div>
            </div>
            <div class="overflow-hidden w-full m-4 flex justify-center bg-white rounded-lg  md:w-[33%] px-8">

                <div class="flex flex-col md:flex-row items-center justify-center  ">
                    <div class="  items-center justify-center flex py-2">
                        <div class="flex flex-col  items-center justify-center text-center">
                            <img src="./image/download (3).png" alt=""
                                class="rounded-full" />
                                <div class="font-bold">3-Export</div>
                            <div class="text-stone-600 font-medium m-2"> Export your model for your projects: sites, apps, and more. You can download your model or host it online.</div>
                            
                            <div class="text-cyan-600 italic"><a href="#"></a></div>
                        </div>
                    </div>

                </div>
            </div>
        </div>
    </div>
</div> 

<div class="flex justify-center bg-white p-4">
    <div class="flex flex-col justify-center items-center ">
        <div class="text-black text-3xl font-medium">What can I use to teach it?
        </div>
        <div class="text-stone-600 font-medium m-2"> Teachable Machine is flexible â€“ use files or capture examples live. Itâ€™s respectful of the way you work. You can even choose to use it entirely on-device, without any webcam or microphone data leaving your computer.
        
        
            <section class="text-gray-600 body-font">
                <div class="container px-5 py-24 mx-auto">
                  <div class="flex flex-wrap -mx-4 -my-8">
                    <div class="py-8 px-4 lg:w-1/3">
                      <div class="h-full flex items-start">
                        
                        <div class="flex-grow pl-6">
                            
                          <h1 class="title-font text-xl font-medium text-gray-900 mb-3">IMAGES</h1>
                          <p class="leading-relaxed mb-5">Teach a model to classify images using files or your webcam.
                        </p>
                          
                        <div>Teachable Machine Image Model</div>
                        <button type="button" onclick="init()">Start</button>
                        <div id="webcam-container"></div>
                        <div id="label-container"></div>
                        <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js"></script>
                        <script src="https://cdn.jsdelivr.net/npm/@teachablemachine/image@latest/dist/teachablemachine-image.min.js"></script>
                        <script type="text/javascript">
                            // More API functions here:
                            // https://github.com/googlecreativelab/teachablemachine-community/tree/master/libraries/image
                        
                            // the link to your model provided by Teachable Machine export panel
                            const URL = "https://teachablemachine.withgoogle.com/models/EhKf8crx9/";
                        
                            let model, webcam, labelContainer, maxPredictions;
                        
                            // Load the image model and setup the webcam
                            async function init() {
                                const modelURL = URL + "model.json";
                                const metadataURL = URL + "metadata.json";
                        
                                // load the model and metadata
                                // Refer to tmImage.loadFromFiles() in the API to support files from a file picker
                                // or files from your local hard drive
                                // Note: the pose library adds "tmImage" object to your window (window.tmImage)
                                model = await tmImage.load(modelURL, metadataURL);
                                maxPredictions = model.getTotalClasses();
                        
                                // Convenience function to setup a webcam
                                const flip = true; // whether to flip the webcam
                                webcam = new tmImage.Webcam(200, 200, flip); // width, height, flip
                                await webcam.setup(); // request access to the webcam
                                await webcam.play();
                                window.requestAnimationFrame(loop);
                        
                                // append elements to the DOM
                                document.getElementById("webcam-container").appendChild(webcam.canvas);
                                labelContainer = document.getElementById("label-container");
                                for (let i = 0; i < maxPredictions; i++) { // and class labels
                                    labelContainer.appendChild(document.createElement("div"));
                                }
                            }
                        
                            async function loop() {
                                webcam.update(); // update the webcam frame
                                await predict();
                                window.requestAnimationFrame(loop);
                            }
                        
                            // run the webcam image through the image model
                            async function predict() {
                                // predict can take in an image, video or canvas html element
                                const prediction = await model.predict(webcam.canvas);
                                for (let i = 0; i < maxPredictions; i++) {
                                    const classPrediction =
                                        prediction[i].className + ": " + prediction[i].probability.toFixed(2);
                                    labelContainer.childNodes[i].innerHTML = classPrediction;
                                }
                            }
                        </script>
                        
                          
                        </div>
                      </div>
                    </div>

                            

                    <div class="py-8 px-4 lg:w-1/3">
                      <div class="h-full flex items-start">
                        
                        <div class="flex-grow pl-6">
                          <h1 class="title-font text-xl font-medium text-gray-900 mb-3">SOUND</h1>
                          <p class="leading-relaxed mb-5">Teach a model to classify audio by recording short sound samples.
                        </p>
                          
                        <div>Teachable Machine Audio Model</div>
                        <button type="button" onclick="init()">Start</button>
                        <div id="label-container"></div>
                        <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.3.1/dist/tf.min.js"></script>
                        <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/speech-commands@0.4.0/dist/speech-commands.min.js"></script>
                        
                        <script type="text/javascript">
                            // more documentation available at
                            // https://github.com/tensorflow/tfjs-models/tree/master/speech-commands
                        
                            // the link to your model provided by Teachable Machine export panel
                            const URL = "https://teachablemachine.withgoogle.com/models/NI4_lb5kV/";
                        
                            async function createModel() {
                                const checkpointURL = URL + "model.json"; // model topology
                                const metadataURL = URL + "metadata.json"; // model metadata
                        
                                const recognizer = speechCommands.create(
                                    "BROWSER_FFT", // fourier transform type, not useful to change
                                    undefined, // speech commands vocabulary feature, not useful for your models
                                    checkpointURL,
                                    metadataURL);
                        
                                // check that model and metadata are loaded via HTTPS requests.
                                await recognizer.ensureModelLoaded();
                        
                                return recognizer;
                            }
                        
                            async function init() {
                                const recognizer = await createModel();
                                const classLabels = recognizer.wordLabels(); // get class labels
                                const labelContainer = document.getElementById("label-container");
                                for (let i = 0; i < classLabels.length; i++) {
                                    labelContainer.appendChild(document.createElement("div"));
                                }
                        
                                // listen() takes two arguments:
                                // 1. A callback function that is invoked anytime a word is recognized.
                                // 2. A configuration object with adjustable fields
                                recognizer.listen(result => {
                                    const scores = result.scores; // probability of prediction for each class
                                    // render the probability scores per class
                                    for (let i = 0; i < classLabels.length; i++) {
                                        const classPrediction = classLabels[i] + ": " + result.scores[i].toFixed(2);
                                        labelContainer.childNodes[i].innerHTML = classPrediction;
                                    }
                                }, {
                                    includeSpectrogram: true, // in case listen should return result.spectrogram
                                    probabilityThreshold: 0.75,
                                    invokeCallbackOnNoiseAndUnknown: true,
                                    overlapFactor: 0.50 // probably want between 0.5 and 0.75. More info in README
                                });
                        
                                // Stop the recognition in 5 seconds.
                                // setTimeout(() => recognizer.stopListening(), 5000);
                            }
                        </script>
                        
                        </div>
                      </div>
                    </div>
                    <div class="py-8 px-4 lg:w-1/3">
                      <div class="h-full flex items-start">
                        <div class="w-12 flex-shrink-0 flex flex-col text-center leading-none">
                        </div>
                        <div class="flex-grow pl-6">
                         
                          <h1 class="title-font text-xl font-medium text-gray-900 mb-3">Posses</h1>
                          <p class="leading-relaxed mb-5">Teach a model to classify body positions using files or striking poses in your webcam. </p>
    
                          <div>Teachable Machine Pose Model</div>
                          <button type="button" onclick="init()">Start</button>
                          <div><canvas id="canvas"></canvas></div>
                          <div id="label-container"></div>
                          <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.3.1/dist/tf.min.js"></script>
                          <script src="https://cdn.jsdelivr.net/npm/@teachablemachine/pose@0.8/dist/teachablemachine-pose.min.js"></script>
                          <script type="text/javascript">
                              // More API functions here:
                              // https://github.com/googlecreativelab/teachablemachine-community/tree/master/libraries/pose
                          
                              // the link to your model provided by Teachable Machine export panel
                              const URL = "https://teachablemachine.withgoogle.com/models/1nwLBoe9F/";
                              let model, webcam, ctx, labelContainer, maxPredictions;
                          
                              async function init() {
                                  const modelURL = URL + "model.json";
                                  const metadataURL = URL + "metadata.json";
                          
                                  // load the model and metadata
                                  // Refer to tmImage.loadFromFiles() in the API to support files from a file picker
                                  // Note: the pose library adds a tmPose object to your window (window.tmPose)
                                  model = await tmPose.load(modelURL, metadataURL);
                                  maxPredictions = model.getTotalClasses();
                          
                                  // Convenience function to setup a webcam
                                  const size = 200;
                                  const flip = true; // whether to flip the webcam
                                  webcam = new tmPose.Webcam(size, size, flip); // width, height, flip
                                  await webcam.setup(); // request access to the webcam
                                  await webcam.play();
                                  window.requestAnimationFrame(loop);
                          
                                  // append/get elements to the DOM
                                  const canvas = document.getElementById("canvas");
                                  canvas.width = size; canvas.height = size;
                                  ctx = canvas.getContext("2d");
                                  labelContainer = document.getElementById("label-container");
                                  for (let i = 0; i < maxPredictions; i++) { // and class labels
                                      labelContainer.appendChild(document.createElement("div"));
                                  }
                              }
                          
                              async function loop(timestamp) {
                                  webcam.update(); // update the webcam frame
                                  await predict();
                                  window.requestAnimationFrame(loop);
                              }
                          
                              async function predict() {
                                  // Prediction #1: run input through posenet
                                  // estimatePose can take in an image, video or canvas html element
                                  const { pose, posenetOutput } = await model.estimatePose(webcam.canvas);
                                  // Prediction 2: run input through teachable machine classification model
                                  const prediction = await model.predict(posenetOutput);
                          
                                  for (let i = 0; i < maxPredictions; i++) {
                                      const classPrediction =
                                          prediction[i].className + ": " + prediction[i].probability.toFixed(2);
                                      labelContainer.childNodes[i].innerHTML = classPrediction;
                                  }
                          
                                  // finally draw the poses
                                  drawPose(pose);
                              }
                          
                              function drawPose(pose) {
                                  if (webcam.canvas) {
                                      ctx.drawImage(webcam.canvas, 0, 0);
                                      // draw the keypoints and skeleton
                                      if (pose) {
                                          const minPartConfidence = 0.5;
                                          tmPose.drawKeypoints(pose.keypoints, minPartConfidence, ctx);
                                          tmPose.drawSkeleton(pose.keypoints, minPartConfidence, ctx);
                                      }
                                  }
                              }
                          </script>
                          

                        </div>
                      </div>
                    </div>
                  </div>
                </div>
              </section>

<script src="https://cdn.tailwindcss.com"></script>
<script src="https://use.fontawesome.com/03f8a0ebd4.js"></script>

<footer class="text-gray-600 body-font">
    <div class="container px-5 py-8 mx-auto flex items-center sm:flex-row flex-col">
      <a class="flex title-font font-medium items-center md:justify-start justify-center text-gray-900">
        <svg xmlns="http://www.w3.org/2000/svg" fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" class="w-10 h-10 text-white p-2 bg-indigo-500 rounded-full" viewBox="0 0 24 24">
          <path d="M12 2L2 7l10 5 10-5-10-5zM2 17l10 5 10-5M2 12l10 5 10-5"></path>
        </svg>
        <span class="ml-3 text-xl">Tailblocks</span>
      </a>
      <p class="text-sm text-gray-500 sm:ml-4 sm:pl-4 sm:border-l-2 sm:border-gray-200 sm:py-2 sm:mt-0 mt-4">Teachable MachineÂ© â€”
        <a href="https://teachablemachine.withgoogle.com/" class="text-gray-600 ml-1" rel="noopener noreferrer" target="_blank">@TeachableMachine</a>
      </p>
      <span class="inline-flex sm:ml-auto sm:mt-0 mt-4 justify-center sm:justify-start">
        <a class="text-gray-500">
          <svg fill="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" class="w-5 h-5" viewBox="0 0 24 24">
            <path d="M18 2h-3a5 5 0 00-5 5v3H7v4h3v8h4v-8h3l1-4h-4V7a1 1 0 011-1h3z"></path>
          </svg>
        </a>
        <a class="ml-3 text-gray-500">
          <svg fill="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" class="w-5 h-5" viewBox="0 0 24 24">
            <path d="M23 3a10.9 10.9 0 01-3.14 1.53 4.48 4.48 0 00-7.86 3v1A10.66 10.66 0 013 4s-4 9 5 13a11.64 11.64 0 01-7 2c9 5 20 0 20-11.5a4.5 4.5 0 00-.08-.83A7.72 7.72 0 0023 3z"></path>
          </svg>
        </a>
        <a class="ml-3 text-gray-500">
          <svg fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" class="w-5 h-5" viewBox="0 0 24 24">
            <rect width="20" height="20" x="2" y="2" rx="5" ry="5"></rect>
            <path d="M16 11.37A4 4 0 1112.63 8 4 4 0 0116 11.37zm1.5-4.87h.01"></path>
          </svg>
        </a>
        <a class="ml-3 text-gray-500">
          <svg fill="currentColor" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="0" class="w-5 h-5" viewBox="0 0 24 24">
            <path stroke="none" d="M16 8a6 6 0 016 6v7h-4v-7a2 2 0 00-2-2 2 2 0 00-2 2v7h-4v-7a6 6 0 016-6zM2 9h4v12H2z"></path>
            <circle cx="4" cy="4" r="2" stroke="none"></circle>
          </svg>
        </a>
      </span>
    </div>
  </footer>


</body>
</html>


<!--<script src="https://cdn.tailwindcss.com"></script>
<script src="https://use.fontawesome.com/03f8a0ebd4.js"></script>--> 
